import pandas as pd
import os
import time

from selenium.webdriver import Firefox
from selenium.webdriver.firefox.options import Options
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException

# Parse XML file and extract relevant interface information
def parse_xml(path_to_xml):
    '''
    Specifically designed to parse a PISA generated xml file
    :return: a df containing select interface features
    '''

    xml_df = pd.read_xml(path_to_xml)

    # Save name of the two proteins participating in the interaction
    proteins = (xml_df.loc[0]['STRUCTURENAME']).split('.')[0]

    first = True
    for i in range(4, ((xml_df.shape[0]))):

        # Save all features from xml_df to vars
        # Save the number of hydrogen bonds
        feature_hbonds = (xml_df.loc[i]['INTERFACENHBONDS'])
        # Save the number of salt bridges
        feature_saltbridges = (xml_df.loc[i]['INTERFACENSALTBRIDGES'])
        # Save the number of salt bridges
        feature_disulfides = (xml_df.loc[i]['INTERFACENDISULFIDEBONDS'])
        # Save the delta g of the interaction
        # The XML file generated by PISA is bad so interface area corresponds with delta G (Aug26,2022)
        feature_deltag = (xml_df.loc[i]['INTERFACEAREA'])
        # Save the p value associated with the delta g of the interaction
        feature_deltagpvalue = (xml_df.loc[i]['INTERFACEDELTAGPVALUE'])
        # Save the average number of residues for the interaction
        feature_avgresidues = (((xml_df.loc[i]['INTERFACENRESIDUES1']) + (xml_df.loc[i]['INTERFACENRESIDUES1'])) / 2)

        if first:
            # Dataframe to save all interactions in, define columns
            df = pd.DataFrame({
                'protA_protB': [],
                'hbonds': [],
                'saltbridges': [],
                'disulfides': [],
                'deltag': [],
                'pvalue': [],
                'avg_residues': [],
            })
            # Add data to columns for the first interaction
            temp_df = pd.DataFrame({
                'protA_protB': [proteins],
                'hbonds': [feature_hbonds],
                'saltbridges': [feature_saltbridges],
                'disulfides': [feature_disulfides],
                'deltag': [feature_deltag],
                'pvalue': [feature_deltagpvalue],
                'avg_residues': [feature_avgresidues],
            })
            first = False
        # For every other interaction add the data
        else:
            temp_df = pd.DataFrame({
                'protA_protB': [proteins],
                'hbonds': [feature_hbonds],
                'saltbridges': [feature_saltbridges],
                'disulfides': [feature_disulfides],
                'deltag': [feature_deltag],
                'pvalue': [feature_deltagpvalue],
                'avg_residues': [feature_avgresidues],
            })
        df = pd.concat([df, temp_df])
        # End of for loop

    # Add weighted delta G to new column
    df['weighted_deltag'] = df.deltag*df.avg_residues

    # Save summaries of features as vars
    sum_hbonds = df['hbonds'].sum()
    sum_saltbridges = df['saltbridges'].sum()
    sum_disulfides = df['disulfides'].sum()
    sum_avg_residues = df['avg_residues'].sum()
    deltag_interaction = ((df['weighted_deltag'].sum()) / (sum_avg_residues))

    # Summarize df in single row of new_df
    new_df = pd.DataFrame({
        'protA_protB': [proteins],
        'hbonds': [sum_hbonds],
        'saltbridges': [sum_saltbridges],
        'disulfides': [sum_disulfides],
        'deltag': [deltag_interaction],
        'avg_residues': [sum_avg_residues],
    })

    # Returns new_df which is a single row summarizing the interaction
    return new_df

# Start of web crawler
# This does not work. The web server does not like massive amounts of requests
def run_pisa_online(pdb_file, xml_files_path):

    # Checks if an element exists on the current page
    def check_exists_by_name(name, cur_driver):
        try:
            cur_driver.find_element(by=By.NAME, value=name)
        except NoSuchElementException:
            return False
        return True

    # Load Firefox without GUI
    opts = Options()
    #opts.add_argument("--headless")
    driver = Firefox(options=opts)

    # Go to the website
    driver.get("https://www.ebi.ac.uk/msd-srv/prot_int/pistart.html")
    driver.implicitly_wait(1)

    driver.find_element(by=By.NAME, value='start_server').click()
    driver.implicitly_wait(2)

    # Find the radio button for uploading a coordinate file
    driver.find_element(by=By.XPATH, value='/html/body/div[2]/div[2]/div/form/table/tbody/tr[4]/td/u/input').click()
    driver.implicitly_wait(3)

    # Upload the PDB file that we want to run PISA on
    driver.find_element(by=By.NAME, value='file_upload').send_keys(pdb_file)
    driver.implicitly_wait(2)
    driver.find_element(by=By.NAME, value='btn_upload').click()

    # Wait for upload to finish and submit button to appear
    while not check_exists_by_name('btn_submit_interfaces', driver):
        pass

    # Submit pdb to PISA
    driver.find_element(by=By.NAME, value='btn_submit_interfaces').click()

    # Figure out if contacts are found
    if driver.find_element(by=By.CLASS_NAME, value='phead').text.startswith('No'):
        print("No interface found")

    # Contacts are found, extract data from XML
    else:
        while not check_exists_by_name('downloadXML', driver):
            pass
        # Get XML data
        driver.find_element(by=By.NAME, value='downloadXML').click()
        driver.implicitly_wait(1)
        # Go to window with XML data
        driver.switch_to.window(driver.window_handles[1])
        time.sleep(3)

        # Saves name of input file for identification
        file_name = pdb_file.split('\\')[-1].split('.')[0]
        print(driver.page_source)
        with open(xml_files_path + '/' + file_name + '.xml', 'w') as file:
            file.write(driver.page_source)

    # Quit driver
    driver.quit()

# Compile features from all xml files (uses function parse_xml)
def compile_features(path_to_xml_folder):
    # Define the master df that all interactions will be saved in
    df_final = pd.DataFrame({
        'protA_protB': [],
        'hbonds': [],
        'saltbridges': [],
        'disulfides': [],
        'deltag': [],
        'avg_residues': [],
    })

    # Loops that goes through the folder with xml files and passes each file to parse_xml
    for file in os.listdir(path_to_xml_folder):
        # Save the full path to the file
        file_path = path_to_xml_folder + '/' + file

        # Run parse_xml and save to temp_df
        temp_df = parse_xml(file_path)

        # Add temp_df to the master df, df
        df_final = pd.concat([df_final, temp_df])

    print('FINISH')
